{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257102e7",
   "metadata": {},
   "source": [
    "# SemanticLayer Troubleshooting Guide\n",
    "\n",
    "This notebook provides step-by-step solutions for common issues when setting up and running the semantic layer project.\n",
    "\n",
    "**Contents:**\n",
    "1. Java/JDK Issues\n",
    "2. PySpark Installation & Configuration\n",
    "3. Missing or Corrupted Data Files\n",
    "4. Virtual Environment Problems\n",
    "5. Test Failures\n",
    "6. Colab-Specific Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae36d8e",
   "metadata": {},
   "source": [
    "## Issue 1: Java/JDK Not Found or Misconfigured\n",
    "\n",
    "### Symptoms\n",
    "- Error: `Java gateway process exited`\n",
    "- Error: `JAVA_HOME not set`\n",
    "- Error: `Unable to locate Java`\n",
    "\n",
    "### Solution by Operating System\n",
    "\n",
    "#### macOS (Homebrew)\n",
    "```bash\n",
    "# Install Java\n",
    "brew install openjdk@11\n",
    "\n",
    "# Find installation path\n",
    "brew --prefix openjdk@11\n",
    "# Returns something like: /usr/local/opt/openjdk@11\n",
    "\n",
    "# Add to shell profile\n",
    "echo 'export PATH=\"/usr/local/opt/openjdk@11/bin:$PATH\"' >> ~/.zshrc\n",
    "echo 'export JAVA_HOME=\"/usr/local/opt/openjdk@11\"' >> ~/.zshrc\n",
    "\n",
    "# Reload shell\n",
    "source ~/.zshrc\n",
    "\n",
    "# Verify\n",
    "java -version\n",
    "```\n",
    "\n",
    "#### Ubuntu/Debian Linux\n",
    "```bash\n",
    "# Update package manager\n",
    "sudo apt-get update\n",
    "\n",
    "# Install OpenJDK\n",
    "sudo apt-get install -y openjdk-11-jdk\n",
    "\n",
    "# Verify\n",
    "java -version\n",
    "\n",
    "# If not in PATH, add to ~/.bashrc\n",
    "echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64' >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "#### Windows (PowerShell)\n",
    "```powershell\n",
    "# Install via Chocolatey (if available)\n",
    "choco install openjdk11\n",
    "\n",
    "# Or download from https://adoptium.net/\n",
    "# Then set environment variable (Admin PowerShell):\n",
    "$env:JAVA_HOME = \"C:\\Program Files\\Java\\jdk-11.0.x\"\n",
    "[System.Environment]::SetEnvironmentVariable(\"JAVA_HOME\", $env:JAVA_HOME, \"User\")\n",
    "\n",
    "# Verify\n",
    "java -version\n",
    "```\n",
    "\n",
    "### Verify Installation\n",
    "After setup, test with:\n",
    "```bash\n",
    "python -c \"from pyspark.sql import SparkSession; SparkSession.builder.master('local').getOrCreate()\"\n",
    "```\n",
    "If no errors appear, Java is properly configured!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f40576",
   "metadata": {},
   "source": [
    "## Issue 2: PySpark Installation Fails or Is Very Slow\n",
    "\n",
    "### Symptoms\n",
    "- `ERROR: Could not find a version that satisfies the requirement pyspark`\n",
    "- Installation hangs for >10 minutes\n",
    "- Disk space errors\n",
    "\n",
    "### Solutions\n",
    "\n",
    "#### Clear pip cache and retry\n",
    "```bash\n",
    "pip cache purge\n",
    "pip install --upgrade pip setuptools wheel\n",
    "pip install -r SemanticLayer/requirements.txt\n",
    "```\n",
    "\n",
    "#### Install specific PySpark version\n",
    "```bash\n",
    "pip install pyspark==3.4.0\n",
    "```\n",
    "\n",
    "#### Check available disk space\n",
    "```bash\n",
    "# macOS/Linux\n",
    "df -h\n",
    "\n",
    "# Windows PowerShell\n",
    "Get-PSDrive C\n",
    "```\n",
    "Ensure >1GB free.\n",
    "\n",
    "#### Use a pre-built wheel (faster)\n",
    "```bash\n",
    "pip install --only-binary :all: pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe62b40",
   "metadata": {},
   "source": [
    "## Issue 3: Missing or Corrupted Data Files\n",
    "\n",
    "### Symptoms\n",
    "- `FileNotFoundError: gold_view.csv not found`\n",
    "- CSV files are empty or have 0 rows\n",
    "- `metadata.json` is malformed\n",
    "\n",
    "### Solution: Re-run ETL\n",
    "\n",
    "#### Option A: Full PySpark ETL (recommended)\n",
    "```bash\n",
    "python SemanticLayer/scripts/process_data_spark.py\n",
    "```\n",
    "\n",
    "#### Option B: Pandas fallback (no Java needed)\n",
    "```bash\n",
    "python SemanticLayer/scripts/process_data.py\n",
    "```\n",
    "\n",
    "#### Option C: Manual reset\n",
    "```bash\n",
    "# Remove old files\n",
    "rm -rf SemanticLayer/data/silver/*\n",
    "rm -rf SemanticLayer/data/gold/*\n",
    "rm SemanticLayer/data/metadata.json\n",
    "\n",
    "# Re-run ETL\n",
    "python SemanticLayer/scripts/process_data_spark.py\n",
    "```\n",
    "\n",
    "#### Verify files were created\n",
    "```bash\n",
    "ls -lah SemanticLayer/data/silver/\n",
    "ls -lah SemanticLayer/data/gold/\n",
    "cat SemanticLayer/data/metadata.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715c53e",
   "metadata": {},
   "source": [
    "## Issue 4: Virtual Environment Problems\n",
    "\n",
    "### Symptoms\n",
    "- `ModuleNotFoundError: No module named 'pyspark'`\n",
    "- Dependencies installed but not found\n",
    "- Wrong Python version\n",
    "\n",
    "### Solution: Recreate Virtual Environment\n",
    "\n",
    "```bash\n",
    "# Deactivate current venv (if active)\n",
    "deactivate\n",
    "\n",
    "# Remove old venv\n",
    "rm -rf .venv\n",
    "\n",
    "# Create fresh venv\n",
    "python -m venv .venv\n",
    "\n",
    "# Activate (choose your OS):\n",
    "# macOS/Linux:\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Windows PowerShell:\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "\n",
    "# Windows Command Prompt:\n",
    ".venv\\Scripts\\activate.bat\n",
    "\n",
    "# Install dependencies\n",
    "pip install --upgrade pip\n",
    "pip install -r SemanticLayer/requirements.txt\n",
    "\n",
    "# Verify\n",
    "python -c \"import pyspark; print(pyspark.__version__)\"\n",
    "```\n",
    "\n",
    "### Check Python version\n",
    "```bash\n",
    "python --version  # Should be 3.8+\n",
    "which python      # Should show path inside .venv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb226c4",
   "metadata": {},
   "source": [
    "## Issue 5: Tests Fail with Assertion Errors\n",
    "\n",
    "### Symptoms\n",
    "- `AssertionError: Expected 145.49, got 145.48`\n",
    "- Test times out after 60 seconds\n",
    "- `ImportError` in test file\n",
    "\n",
    "### Solution: Debug ETL Output\n",
    "\n",
    "```bash\n",
    "# 1. Check if gold_view.csv exists and has data\n",
    "head -20 SemanticLayer/data/gold/gold_view.csv\n",
    "\n",
    "# 2. View as pandas to check values\n",
    "python -c \"import pandas as pd; print(pd.read_csv('SemanticLayer/data/gold/gold_view.csv').to_string())\"\n",
    "\n",
    "# 3. Check metadata\n",
    "cat SemanticLayer/data/metadata.json\n",
    "\n",
    "# 4. Re-run ETL with verbose output\n",
    "python -u SemanticLayer/scripts/process_data_spark.py\n",
    "\n",
    "# 5. Run specific test with verbose output\n",
    "pytest -vv SemanticLayer/tests/test_etl.py::test_gold_view_values\n",
    "```\n",
    "\n",
    "### Common Assertion Causes\n",
    "- Floating-point precision: Expected `145.50`, got `145.4999999` (use `pytest.approx()`)\n",
    "- Data not re-generated: Run `process_data_spark.py` again\n",
    "- Old cached data: Delete `SemanticLayer/data/` and rebuild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e63ec5",
   "metadata": {},
   "source": [
    "## Issue 6: Colab-Specific Issues\n",
    "\n",
    "### Symptom 1: \"gold_view.csv not found\" in Colab\n",
    "\n",
    "**Solution:** Mount Google Drive\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Then read from mounted drive\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/gold_view.csv')\n",
    "```\n",
    "\n",
    "Or upload the file manually:\n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "# Then select gold_view.csv from your computer\n",
    "```\n",
    "\n",
    "### Symptom 2: Java errors in Colab\n",
    "\n",
    "**Solution:** Use DuckDB instead (no Java)\n",
    "```python\n",
    "# Install DuckDB\n",
    "!pip install duckdb\n",
    "\n",
    "# No need for PySpark in Colab; use DuckDB for SQL queries\n",
    "import duckdb\n",
    "duckdb.sql(\"SELECT * FROM 'gold_view.csv' LIMIT 5\").show()\n",
    "```\n",
    "\n",
    "### Symptom 3: Dependencies not installing\n",
    "\n",
    "```python\n",
    "# Upgrade pip first\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Then install all dependencies\n",
    "!pip install pandas duckdb pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15d205",
   "metadata": {},
   "source": [
    "## Quick Diagnostic Script\n",
    "\n",
    "Run this script to check your setup:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SEMANTIC LAYER SETUP DIAGNOSTIC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"\\n✓ Python version: {sys.version}\")\n",
    "if sys.version_info < (3, 8):\n",
    "    print(\"  ⚠ WARNING: Python 3.8+ required\")\n",
    "\n",
    "# Check Java\n",
    "try:\n",
    "    java_version = subprocess.check_output(['java', '-version'], stderr=subprocess.STDOUT).decode()\n",
    "    print(f\"✓ Java installed: {java_version.split()[0]}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"✗ Java NOT found (required for PySpark)\")\n",
    "\n",
    "# Check required packages\n",
    "packages = ['pandas', 'pyspark', 'duckdb', 'pytest']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"✓ {pkg} installed\")\n",
    "    except ImportError:\n",
    "        print(f\"✗ {pkg} NOT installed\")\n",
    "\n",
    "# Check data files\n",
    "data_files = [\n",
    "    'SemanticLayer/data/silver/customers_silver.csv',\n",
    "    'SemanticLayer/data/silver/transactions_silver.csv',\n",
    "    'SemanticLayer/data/gold/gold_view.csv',\n",
    "    'SemanticLayer/data/metadata.json'\n",
    "]\n",
    "\n",
    "print(\"\\nData files:\")\n",
    "for f in data_files:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"✓ {f} ({size} bytes)\")\n",
    "    else:\n",
    "        print(f\"✗ {f} (missing)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "```\n",
    "\n",
    "Save as `diagnostic.py` and run:\n",
    "```bash\n",
    "python diagnostic.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6311251a",
   "metadata": {},
   "source": [
    "## Still Stuck?\n",
    "\n",
    "1. **Post the error message** with context (OS, Python version, command)\n",
    "2. **Run the diagnostic script** above and share output\n",
    "3. **Check the main SETUP_GUIDE.md** in the repo root\n",
    "4. **Open an issue** on GitHub with: OS, error logs, and diagnostic output\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- [PySpark Troubleshooting](https://spark.apache.org/docs/latest/)\n",
    "- [Java Installation Guide](https://www.java.com/en/download/help/download_options.html)\n",
    "- [DuckDB Documentation](https://duckdb.org/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
